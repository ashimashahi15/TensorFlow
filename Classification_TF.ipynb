{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/PB+OhkLWo0V0YCaLi187"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# INTRODUCTION"],"metadata":{"id":"1inEMVq2wRUz"}},{"cell_type":"markdown","source":["Implementation\n","1. Is mostly an exercise in \"API hunting\"\n","2. The actual math is not written in code\n","3. Your job is to find the function that implements the math in question\n","4. so the equation y = mx  + b is implemented in Keras layer called Dense\n","5. Tensorflow code is always written in keras layers"],"metadata":{"id":"J9TjQ-IqmRKO"}},{"cell_type":"markdown","source":["Steps to be followed:\n","1. Load the data (X and Y)- may involve transforming the data\n","2. Instantiate the model\n","3. Train(\"fir\") the model\n","4. Evaluate the model\n"],"metadata":{"id":"xeBd-OiqlXde"}},{"cell_type":"markdown","source":["Step 1 \n","\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Input(shape=(D,)),\n","  tf.keras.layers.Dense(1, activation='sigmoid')\n","\n","  ])"],"metadata":{"id":"-mnnBJ7jn8J2"}},{"cell_type":"markdown","source":["Step 2\n","Training/Fitting\n","\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","\n","r = model.fit(X_train, Y_train,\n","          validation_data=(X_test, y_test),\n","          epochs=100)\n","\n","\n","**To get history of training process we will use history function**\n","\n","\n","plt.plot(r.history['loss'], label ='loss')\n","plt.plot(r.history['val_loss'], label='val_loss')"],"metadata":{"id":"aLDf0yoko9A1"}},{"cell_type":"markdown","source":["# LOADING & UNDERSTANDING THE DATASET "],"metadata":{"id":"Bc8MYLtbwDwG"}},{"cell_type":"code","execution_count":30,"metadata":{"id":"RAkISFixkxvE","executionInfo":{"status":"ok","timestamp":1676446122263,"user_tz":480,"elapsed":599,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}}},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["from sklearn.datasets import load_breast_cancer"],"metadata":{"id":"uydVDqOLopqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = load_breast_cancer()\n"],"metadata":{"id":"GrYcbaUBt_ZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DuDsxobKuHNY","executionInfo":{"status":"ok","timestamp":1676441867465,"user_tz":-330,"elapsed":8,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"baa290cd-7572-4405-e505-8bb7c38fb614"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n","         1.189e-01],\n","        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n","         8.902e-02],\n","        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n","         8.758e-02],\n","        ...,\n","        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n","         7.820e-02],\n","        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n","         1.240e-01],\n","        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n","         7.039e-02]]),\n"," 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n","        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n","        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n","        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n","        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n","        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n","        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n","        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n"," 'frame': None,\n"," 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n"," 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n"," 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n","        'mean smoothness', 'mean compactness', 'mean concavity',\n","        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n","        'radius error', 'texture error', 'perimeter error', 'area error',\n","        'smoothness error', 'compactness error', 'concavity error',\n","        'concave points error', 'symmetry error',\n","        'fractal dimension error', 'worst radius', 'worst texture',\n","        'worst perimeter', 'worst area', 'worst smoothness',\n","        'worst compactness', 'worst concavity', 'worst concave points',\n","        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n"," 'filename': 'breast_cancer.csv',\n"," 'data_module': 'sklearn.datasets.data'}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["type(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1d2-WbWuNCP","executionInfo":{"status":"ok","timestamp":1676441920639,"user_tz":-330,"elapsed":4,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"1dc34f8c-f0eb-451b-9220-c50e8d6e2ecb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sklearn.utils.Bunch"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHPdbfvZuT09","executionInfo":{"status":"ok","timestamp":1676441943280,"user_tz":-330,"elapsed":4,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"d9a3e319-9fff-415a-ed94-ac92255771cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["data.target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cv71glKkudo7","executionInfo":{"status":"ok","timestamp":1676441978382,"user_tz":-330,"elapsed":397,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"d80b29fc-c849-4a94-9d6a-6e2bbc15e95f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n","       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n","       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n","       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n","       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n","       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n","       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["data.data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZuUAKt1Wuma8","executionInfo":{"status":"ok","timestamp":1676442012194,"user_tz":-330,"elapsed":3,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"a4da52fc-b429-4b79-def2-5edd4c1be3a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n","        1.189e-01],\n","       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n","        8.902e-02],\n","       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n","        8.758e-02],\n","       ...,\n","       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n","        7.820e-02],\n","       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n","        1.240e-01],\n","       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n","        7.039e-02]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["data.target_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaqo6bjRuwJo","executionInfo":{"status":"ok","timestamp":1676442086676,"user_tz":-330,"elapsed":3,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"cfd89e70-34e8-49e1-cd73-ab0d448ec1b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['malignant', 'benign'], dtype='<U9')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["data.feature_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMN4jzgbu8fb","executionInfo":{"status":"ok","timestamp":1676442112171,"user_tz":-330,"elapsed":4,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"2a072cb2-9574-4fd4-d6f5-1663ff571893"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n","       'mean smoothness', 'mean compactness', 'mean concavity',\n","       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n","       'radius error', 'texture error', 'perimeter error', 'area error',\n","       'smoothness error', 'compactness error', 'concavity error',\n","       'concave points error', 'symmetry error',\n","       'fractal dimension error', 'worst radius', 'worst texture',\n","       'worst perimeter', 'worst area', 'worst smoothness',\n","       'worst compactness', 'worst concavity', 'worst concave points',\n","       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["data.filename"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"KlGtLRoOvG8F","executionInfo":{"status":"ok","timestamp":1676442202591,"user_tz":-330,"elapsed":6,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"108316ad-8313-480c-b9ed-2b0debd56c8f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'breast_cancer.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["data.data_module"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"70FJCpdcvex0","executionInfo":{"status":"ok","timestamp":1676442225772,"user_tz":-330,"elapsed":7,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"137a2847-831a-45bc-8823-15dc70974aa6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'sklearn.datasets.data'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["data.data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cag6ON_ovka4","executionInfo":{"status":"ok","timestamp":1676442245858,"user_tz":-330,"elapsed":4,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"dfd8cb2c-03bb-4c48-df0b-d3960b725e7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(569, 30)"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# SPLITTING AND SCALING THE DATA"],"metadata":{"id":"3ADABxFXwbMx"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(data.data, data.target,test_size=.33)"],"metadata":{"id":"vtkrAhWbvpAI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N, D = X_train.shape"],"metadata":{"id":"BELk5tLiwoNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N,D"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0Llf_OWxWTH","executionInfo":{"status":"ok","timestamp":1676442697635,"user_tz":-330,"elapsed":4,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"5820a8f0-2bd5-47f8-95c2-3c88468d16cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(381, 30)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","\n","X_train = scaler.fit_transform(X_train)\n"],"metadata":{"id":"P-fHKFXsxXgF","executionInfo":{"status":"ok","timestamp":1676445670857,"user_tz":480,"elapsed":849,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["The fit method is calculating the mean and variance of each of the features present in our data. The transform method is transforming all the features using the respective mean and variance.\n","\n","\n","Now, we want scaling to be applied to our test data too and at the same time do not want to be biased with our model. We want our test data to be a completely new and a surprise set for our model. The transform method helps us in this case."],"metadata":{"id":"XujvE_K_8NDc"}},{"cell_type":"markdown","source":["transform()\n","\n","Using the transform method we can use the same mean and variance as it is calculated from our training data to transform our test data. Thus, the parameters learned by our model using the training data will help us to transform our test data."],"metadata":{"id":"V2UqFbAu8TgL"}},{"cell_type":"markdown","source":["If we will use the fit method on our test data too, we will compute a new mean and variance that is a new scale for each feature and will let our model learn about our test data too. Thus, what we want to keep as a surprise is no longer unknown to our model and we will not get a good estimate of how our model is performing on the test (unseen) data which is the ultimate goal of building a model using machine learning algorithm."],"metadata":{"id":"xMH8xTkK8gFz"}},{"cell_type":"code","source":["X_test = scaler.transform(X_test)"],"metadata":{"id":"J6kPFzAa8qAD","executionInfo":{"status":"ok","timestamp":1676445702671,"user_tz":480,"elapsed":7,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# MODEL BUILDING"],"metadata":{"id":"sLJyBF409j6J"}},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","         tf.keras.layers.Input(shape=(D,)),\n","         tf.keras.layers.Dense(1, activation='sigmoid')\n","         ])"],"metadata":{"id":"u6c6f63bxyGa","executionInfo":{"status":"ok","timestamp":1676446153508,"user_tz":480,"elapsed":1292,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["## model = tf.keras.models.Sequential([\n","     #   model.add(tf.keras.layers.Dense(1, Input_shape=(D,), activation='sigmoid')])"],"metadata":{"id":"sFVS86qR-i36"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"pk5ath-D_kzL","executionInfo":{"status":"ok","timestamp":1676446530843,"user_tz":480,"elapsed":445,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["r = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4jCsdJJ__bs","executionInfo":{"status":"ok","timestamp":1676447252182,"user_tz":480,"elapsed":8857,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"a77acf46-c1a5-4c02-cd29-c949c90ed2ef"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","12/12 [==============================] - 1s 24ms/step - loss: 0.6903 - accuracy: 0.5564 - val_loss: 0.6397 - val_accuracy: 0.6383\n","Epoch 2/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.6325 - val_loss: 0.5760 - val_accuracy: 0.6968\n","Epoch 3/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7008 - val_loss: 0.5222 - val_accuracy: 0.7766\n","Epoch 4/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7612 - val_loss: 0.4787 - val_accuracy: 0.8191\n","Epoch 5/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.8005 - val_loss: 0.4411 - val_accuracy: 0.8404\n","Epoch 6/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.8268 - val_loss: 0.4094 - val_accuracy: 0.8670\n","Epoch 7/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8451 - val_loss: 0.3821 - val_accuracy: 0.8936\n","Epoch 8/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8530 - val_loss: 0.3588 - val_accuracy: 0.9043\n","Epoch 9/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8609 - val_loss: 0.3382 - val_accuracy: 0.9096\n","Epoch 10/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8688 - val_loss: 0.3203 - val_accuracy: 0.9096\n","Epoch 11/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.8793 - val_loss: 0.3039 - val_accuracy: 0.9149\n","Epoch 12/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.3458 - accuracy: 0.8871 - val_loss: 0.2900 - val_accuracy: 0.9255\n","Epoch 13/100\n","12/12 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.8950 - val_loss: 0.2773 - val_accuracy: 0.9362\n","Epoch 14/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.3215 - accuracy: 0.8976 - val_loss: 0.2655 - val_accuracy: 0.9362\n","Epoch 15/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.3106 - accuracy: 0.9003 - val_loss: 0.2549 - val_accuracy: 0.9415\n","Epoch 16/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.3011 - accuracy: 0.9134 - val_loss: 0.2454 - val_accuracy: 0.9468\n","Epoch 17/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.2917 - accuracy: 0.9213 - val_loss: 0.2365 - val_accuracy: 0.9468\n","Epoch 18/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.2832 - accuracy: 0.9265 - val_loss: 0.2282 - val_accuracy: 0.9468\n","Epoch 19/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.2751 - accuracy: 0.9291 - val_loss: 0.2206 - val_accuracy: 0.9521\n","Epoch 20/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.2679 - accuracy: 0.9239 - val_loss: 0.2138 - val_accuracy: 0.9574\n","Epoch 21/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2607 - accuracy: 0.9239 - val_loss: 0.2071 - val_accuracy: 0.9628\n","Epoch 22/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2543 - accuracy: 0.9239 - val_loss: 0.2012 - val_accuracy: 0.9628\n","Epoch 23/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2479 - accuracy: 0.9239 - val_loss: 0.1954 - val_accuracy: 0.9681\n","Epoch 24/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.2422 - accuracy: 0.9318 - val_loss: 0.1900 - val_accuracy: 0.9681\n","Epoch 25/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9318 - val_loss: 0.1854 - val_accuracy: 0.9681\n","Epoch 26/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9344 - val_loss: 0.1805 - val_accuracy: 0.9734\n","Epoch 27/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.2264 - accuracy: 0.9370 - val_loss: 0.1759 - val_accuracy: 0.9734\n","Epoch 28/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.9370 - val_loss: 0.1721 - val_accuracy: 0.9734\n","Epoch 29/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.2173 - accuracy: 0.9370 - val_loss: 0.1682 - val_accuracy: 0.9734\n","Epoch 30/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2128 - accuracy: 0.9370 - val_loss: 0.1644 - val_accuracy: 0.9734\n","Epoch 31/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.9370 - val_loss: 0.1608 - val_accuracy: 0.9734\n","Epoch 32/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2049 - accuracy: 0.9370 - val_loss: 0.1577 - val_accuracy: 0.9734\n","Epoch 33/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.2012 - accuracy: 0.9370 - val_loss: 0.1542 - val_accuracy: 0.9734\n","Epoch 34/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1975 - accuracy: 0.9423 - val_loss: 0.1515 - val_accuracy: 0.9734\n","Epoch 35/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1942 - accuracy: 0.9475 - val_loss: 0.1487 - val_accuracy: 0.9734\n","Epoch 36/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1910 - accuracy: 0.9475 - val_loss: 0.1461 - val_accuracy: 0.9734\n","Epoch 37/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.9475 - val_loss: 0.1434 - val_accuracy: 0.9734\n","Epoch 38/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1848 - accuracy: 0.9475 - val_loss: 0.1409 - val_accuracy: 0.9734\n","Epoch 39/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1819 - accuracy: 0.9501 - val_loss: 0.1383 - val_accuracy: 0.9734\n","Epoch 40/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1792 - accuracy: 0.9528 - val_loss: 0.1363 - val_accuracy: 0.9734\n","Epoch 41/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1765 - accuracy: 0.9528 - val_loss: 0.1341 - val_accuracy: 0.9734\n","Epoch 42/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1738 - accuracy: 0.9528 - val_loss: 0.1321 - val_accuracy: 0.9734\n","Epoch 43/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.9606 - val_loss: 0.1300 - val_accuracy: 0.9734\n","Epoch 44/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9659 - val_loss: 0.1281 - val_accuracy: 0.9734\n","Epoch 45/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1669 - accuracy: 0.9659 - val_loss: 0.1263 - val_accuracy: 0.9734\n","Epoch 46/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1646 - accuracy: 0.9659 - val_loss: 0.1245 - val_accuracy: 0.9734\n","Epoch 47/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1625 - accuracy: 0.9685 - val_loss: 0.1227 - val_accuracy: 0.9734\n","Epoch 48/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1605 - accuracy: 0.9685 - val_loss: 0.1212 - val_accuracy: 0.9734\n","Epoch 49/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1586 - accuracy: 0.9685 - val_loss: 0.1195 - val_accuracy: 0.9734\n","Epoch 50/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9685 - val_loss: 0.1180 - val_accuracy: 0.9734\n","Epoch 51/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9685 - val_loss: 0.1165 - val_accuracy: 0.9734\n","Epoch 52/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.9685 - val_loss: 0.1149 - val_accuracy: 0.9734\n","Epoch 53/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1514 - accuracy: 0.9685 - val_loss: 0.1135 - val_accuracy: 0.9734\n","Epoch 54/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9685 - val_loss: 0.1123 - val_accuracy: 0.9734\n","Epoch 55/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9685 - val_loss: 0.1111 - val_accuracy: 0.9734\n","Epoch 56/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.9685 - val_loss: 0.1098 - val_accuracy: 0.9734\n","Epoch 57/100\n","12/12 [==============================] - 0s 7ms/step - loss: 0.1450 - accuracy: 0.9685 - val_loss: 0.1087 - val_accuracy: 0.9734\n","Epoch 58/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 0.9685 - val_loss: 0.1076 - val_accuracy: 0.9734\n","Epoch 59/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9685 - val_loss: 0.1064 - val_accuracy: 0.9734\n","Epoch 60/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1407 - accuracy: 0.9685 - val_loss: 0.1052 - val_accuracy: 0.9734\n","Epoch 61/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.9711 - val_loss: 0.1044 - val_accuracy: 0.9734\n","Epoch 62/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9711 - val_loss: 0.1034 - val_accuracy: 0.9734\n","Epoch 63/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1368 - accuracy: 0.9711 - val_loss: 0.1024 - val_accuracy: 0.9734\n","Epoch 64/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9711 - val_loss: 0.1013 - val_accuracy: 0.9734\n","Epoch 65/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1343 - accuracy: 0.9711 - val_loss: 0.1005 - val_accuracy: 0.9734\n","Epoch 66/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9711 - val_loss: 0.0998 - val_accuracy: 0.9734\n","Epoch 67/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1320 - accuracy: 0.9711 - val_loss: 0.0988 - val_accuracy: 0.9734\n","Epoch 68/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9764 - val_loss: 0.0980 - val_accuracy: 0.9734\n","Epoch 69/100\n","12/12 [==============================] - 0s 7ms/step - loss: 0.1298 - accuracy: 0.9764 - val_loss: 0.0971 - val_accuracy: 0.9734\n","Epoch 70/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.9764 - val_loss: 0.0963 - val_accuracy: 0.9734\n","Epoch 71/100\n","12/12 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9738 - val_loss: 0.0956 - val_accuracy: 0.9734\n","Epoch 72/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1267 - accuracy: 0.9738 - val_loss: 0.0948 - val_accuracy: 0.9734\n","Epoch 73/100\n","12/12 [==============================] - 0s 7ms/step - loss: 0.1257 - accuracy: 0.9738 - val_loss: 0.0942 - val_accuracy: 0.9734\n","Epoch 74/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.9738 - val_loss: 0.0936 - val_accuracy: 0.9734\n","Epoch 75/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9764 - val_loss: 0.0929 - val_accuracy: 0.9734\n","Epoch 76/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9764 - val_loss: 0.0923 - val_accuracy: 0.9734\n","Epoch 77/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.9764 - val_loss: 0.0918 - val_accuracy: 0.9734\n","Epoch 78/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9764 - val_loss: 0.0911 - val_accuracy: 0.9734\n","Epoch 79/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.9764 - val_loss: 0.0904 - val_accuracy: 0.9734\n","Epoch 80/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9764 - val_loss: 0.0899 - val_accuracy: 0.9734\n","Epoch 81/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9764 - val_loss: 0.0894 - val_accuracy: 0.9734\n","Epoch 82/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9790 - val_loss: 0.0888 - val_accuracy: 0.9734\n","Epoch 83/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9790 - val_loss: 0.0882 - val_accuracy: 0.9734\n","Epoch 84/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.9790 - val_loss: 0.0877 - val_accuracy: 0.9734\n","Epoch 85/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.9790 - val_loss: 0.0872 - val_accuracy: 0.9734\n","Epoch 86/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.9790 - val_loss: 0.0868 - val_accuracy: 0.9734\n","Epoch 87/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9790 - val_loss: 0.0863 - val_accuracy: 0.9734\n","Epoch 88/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.9790 - val_loss: 0.0859 - val_accuracy: 0.9734\n","Epoch 89/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9790 - val_loss: 0.0853 - val_accuracy: 0.9734\n","Epoch 90/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9790 - val_loss: 0.0849 - val_accuracy: 0.9734\n","Epoch 91/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.9790 - val_loss: 0.0845 - val_accuracy: 0.9734\n","Epoch 92/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9790 - val_loss: 0.0840 - val_accuracy: 0.9734\n","Epoch 93/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9790 - val_loss: 0.0837 - val_accuracy: 0.9734\n","Epoch 94/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9734\n","Epoch 95/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9790 - val_loss: 0.0829 - val_accuracy: 0.9734\n","Epoch 96/100\n","12/12 [==============================] - 0s 7ms/step - loss: 0.1082 - accuracy: 0.9790 - val_loss: 0.0825 - val_accuracy: 0.9734\n","Epoch 97/100\n","12/12 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9734\n","Epoch 98/100\n","12/12 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9790 - val_loss: 0.0819 - val_accuracy: 0.9734\n","Epoch 99/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.9790 - val_loss: 0.0813 - val_accuracy: 0.9734\n","Epoch 100/100\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9734\n"]}]},{"cell_type":"markdown","source":["model.fit() is a method in machine learning that is used to train a machine learning model. When you build a machine learning model, you typically start with some initial weights or parameters, and then iteratively adjust these parameters in order to improve the model's predictions. This process is known as training.\n","\n","The model.fit() method is used to perform the training process. It takes as input a set of training data, along with the desired outputs for that data (also known as labels). The method then uses an optimization algorithm (such as stochastic gradient descent) to adjust the model's parameters to minimize the difference between the predicted outputs and the actual labels.\n","\n"],"metadata":{"id":"W8yG8NAvCHiC"}},{"cell_type":"markdown","source":["\n","\n","The model.fit() method typically returns a History object that contains the values of the loss function and metrics at each epoch of the training process. This object can be used to plot the learning curves of the model, which show how the loss and metrics change over the course of the training process. The learning curves are useful for diagnosing problems with the model (such as overfitting or underfitting) and for optimizing the hyperparameters of the model (such as the learning rate or regularization strength).\n","\n","In addition to the loss function and metrics, model.fit() may also compute and report other statistics, such as the gradients of the parameters with respect to the loss function, the update steps taken by the optimization algorithm, and the training time per epoch. These statistics can be useful for understanding the behavior of the optimization algorithm and for diagnosing issues with the training process.\n","\n"],"metadata":{"id":"N6rxXpVJCJOp"}},{"cell_type":"code","source":["print(\"Train score:\", model.evaluate(X_train, y_train)),\n","print(\"Test score:\", model.evaluate(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcKNEErGC7eA","executionInfo":{"status":"ok","timestamp":1676450955174,"user_tz":480,"elapsed":1868,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"85e13507-5563-45dc-df3b-5829a46b0fd7"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9790\n","Train score: [0.10557670146226883, 0.9790025949478149]\n","6/6 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9734\n","Test score: [0.08105433732271194, 0.9734042286872864]\n"]}]},{"cell_type":"markdown","source":["model.evaluate() is a method in machine learning that is used to evaluate the performance of a trained machine learning model. The method takes as input a set of test data, along with the desired outputs for that data (also known as labels). It then uses the trained model to make predictions on the test data, and compares the predicted outputs to the actual labels in order to compute various performance metrics.\n","\n","The model.evaluate() method typically returns a dictionary of metrics that are computed on the test data. The metrics may include measures of the model's accuracy, precision, recall, F1 score, and others, depending on the specific problem being addressed. These metrics are used to assess the quality of the model's predictions on the test data, and to compare the performance of different models or hyperparameters.\n","\n","dictionary of metrics means\n","When you call model.evaluate() in machine learning, it typically returns a dictionary of metrics that are computed on the test data. The dictionary contains a key-value pair for each metric, where the key is the name of the metric and the value is the computed value of the metric.\n","\n","The specific metrics that are computed depend on the problem being addressed and the type of model being used. For example, for a classification problem, common metrics might include accuracy, precision, recall, F1 score, and confusion matrix. For a regression problem, common metrics might include mean squared error, mean absolute error, R-squared score, and explained variance.\n","\n"],"metadata":{"id":"eq-iSH5yCPVB"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(r.history['loss'], label='loss')\n","plt.plot(r.history['val_loss'], label='val_loss')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"NtVd9PrKabx3","executionInfo":{"status":"ok","timestamp":1676455055991,"user_tz":480,"elapsed":1651,"user":{"displayName":"ashima shahi","userId":"05738012176296727869"}},"outputId":"832ae615-b11c-40a6-9d87-20ad52ea3496"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f22777da5e0>]"]},"metadata":{},"execution_count":41},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["The loss curve shows how the training and validation loss changed over each epoch (or iteration) during the training process. A decreasing training loss and validation loss indicate that the model is improving its performance. However, if the validation loss starts to increase while the training loss is decreasing, this can be a sign of overfitting, which means the model is starting to memorize the training data rather than generalizing well to new data.\n","\n","\n","It's important to note that the history plot is just one tool for evaluating a model's performance during training, and it should be used in conjunction with other evaluation methods, such as cross-validation and testing on a held-out dataset. Additionally, the history plot only provides information about the performance during training, and it may not accurately reflect the model's performance in the real world.\n","\n","\n","\n","\n"],"metadata":{"id":"0FxOg6HMhwuD"}},{"cell_type":"code","source":[],"metadata":{"id":"xUWiCBKDgI-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cE5sbblRh5is"},"execution_count":null,"outputs":[]}]}